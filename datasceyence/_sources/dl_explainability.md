# Explainable AI

## Skill

### Description
Feature visualisation.

### Goals
* I know what saliency maps are.
* I know what guided backpropagation is.


### Links
* Distilled Notes for Stanford CS231n: Convolutional Neural Networks for Visual Recognition (Chadha, 2020) - https://aman.ai/cs231n/visualization/
* Stanford CS231n: Lecture 14: Visualizing and Understanding (Fei-Fei Li & Justin Johnson & Serena Yeung, 2019) - http://cs231n.stanford.edu/slides/2019/cs231n_2019_lecture13.pdf
* Article: Feature Visualization (Olah et al., 2017) - https://distill.pub/2017/feature-visualization/
* Book (GitHub): Interpretable Machine Learning: A Guide for Making Black Box Models Explainable (Molnar) - https://christophm.github.io/interpretable-ml-book/
* Code (GitHub): Convolutional Neural Network Visualizations (Ozbulak, 2019) - https://github.com/utkuozbulak/pytorch-cnn-visualizations
* https://towardsdatascience.com/explainable-neural-networks-recent-advancements-part-4-73cacc910fef

## Background
* Layer-wise Relevance Propagation
* Taylor Decomposition - Integrated Gradients (2017)
* Deep LiFT
* LIME, SHAP 