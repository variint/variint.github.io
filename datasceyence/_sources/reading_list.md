# My reading list

## Publications

Everything that is not part of another chapter


### 2024
| Paper | reference | status | learned |
|---|---|---|---|
| Grokking |
| Multi-modality |
| Capsule networks |
| Neural Networks and the Chomsky Hierarchy |
| Break It Down: Evidence for Structural Compositionality in Neural Networks |


### 2023
| Paper | reference | status | learned |
|---|---|---|---|
| Perspectives on the State and Future of Deep Learning--2023 | {cite}`goldblum2023perspectives` | todo ||
| Riemann || todo | |
| 2019 - ICCV - multi-exit training - Distillation-Based Training for Multi-Exit Architectures || todo ||
| Two-Stream Transformer Architecture for Long Form Video Understanding | | done | spatial and temporal transformer architecture, for video analysis |
| PHiSeg: Capturing Uncertainty in Medical Image Segmentation | {cite}`baumgartner2019phiseg` | done | uncertainty in segmentation |
| A Survey of Reasoning with Foundation Models ||||
| Interpretability Beyond Feature Attribution: Quantitative Testing with Concept Activation Vectors (TCAV) ||||
| Designing and Interpreting Probes with Control Tasks ||||
| FIND: A Function Description Benchmark for Evaluating Interpretability Methods ||||
| Disentangling visual and written concepts in CLIP | https://joaanna.github.io/disentangling_spelling_in_clip/ |||
| Natural Language Descriptions of Deep Visual Features | http://milan.csail.mit.edu/ |||
| Network Dissection: Quantifying Interpretability of Deep Visual Representations | http://netdissect.csail.mit.edu/ |||
| CRESPR: Modular sparsification of DNNs to improve pruning performance and model interpretability ||||
| Concept attribution: Explaining CNN decisions to physicians ||||





## References
```{bibliography}
:filter: docname in docnames
```