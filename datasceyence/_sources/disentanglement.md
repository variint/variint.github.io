# Disentangled learning

## Skill

### Description:

### Goals:

### Links:
* Induction, Inductive Biases, and Infusing Knowledge into Learned Representations https://sgfin.github.io/2020/06/22/Induction-Intro/


## Introduction

### Domain Shift

Style

Content



### Domain Knowledge

Inductive Bias

Inductive bias refers to a set of assumptions made by a learning algorithm in order to predict outputs of given inputs that it has not encountered. The goal is to generalize a finite set of observation (training data) into a general model of the domain. 

There are two types of inductive biases. Relational inductive biases represent the relationship between entities in a network. Non-relational inductive biases is a set of techniques that further constrain the learning algorithm.



<!-- We can categorize inductive biases into two different groups called relational and non-relational. The former represents the relationship between entities in the network, while the latter is a set of techniques that further constrain the learning algorithm. -->


<!-- Without a bias of that kind, induction would not be possible, since the observations can normally be generalized in many ways. Treating all these possibilities in equally, i.e., without any bias in the sense of a preference for specific types of generalization (reflecting background knowledge about the target function to be learned), predictions for new situations could not be made. -->




### Disentanglement


### Representation Learning




## Architecture

### Generative Models

### Encoder

### Decoder

### Latent Space


## Applications

### Synthesis

Image 2 Image translation   

### Segmentation

