# Disentangled learning

## Skill

### Description

### Goals
* I know metrics for measuring the level of disentanglement.

### Links
* Modified PhD thesis excerpt (GitHub): Induction, Inductive Biases, and Infusing Knowledge into Learned Representations (Finlayson, 2020) - https://sgfin.github.io/2020/06/22/Induction-Intro/
* Review Paper: Review of Disentanglement Approaches for Medical Applications (Fragemann, 2022) - https://arxiv.org/abs/2203.11132
* Review paper: Learning Disentangled Representations in the Imaging Domain (Liu, 2022) - https://arxiv.org/abs/2108.12043
* Book (GitHub): Network Dissection (Molnar) - https://christophm.github.io/interpretable-ml-book/cnn-features.html#network-dissection



## Background

### Domain Shift

Style

Content


### Domain Knowledge

Inductive Bias

Inductive bias refers to a set of assumptions made by a learning algorithm in order to predict outputs of given inputs that it has not encountered. The goal is to generalize a finite set of observation (training data) into a general model of the domain. 

There are two types of inductive biases. Relational inductive biases represent the relationship between entities in a network. Non-relational inductive biases is a set of techniques that further constrain the learning algorithm.



<!-- We can categorize inductive biases into two different groups called relational and non-relational. The former represents the relationship between entities in the network, while the latter is a set of techniques that further constrain the learning algorithm. -->


<!-- Without a bias of that kind, induction would not be possible, since the observations can normally be generalized in many ways. Treating all these possibilities in equally, i.e., without any bias in the sense of a preference for specific types of generalization (reflecting background knowledge about the target function to be learned), predictions for new situations could not be made. -->




### Disentanglement


### Representation Learning




## Architecture

### Generative Models

Variational Auto Encoders

Masked Variational Auto Encoders



### Encoder

### Decoder

### Latent Space




## Applications

### Synthesis

Image 2 Image translation   

### Segmentation

