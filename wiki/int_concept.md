# Interpretability / Concept alignment

## Concept learning
Concept learning has the goal of learning human-understandable concepts.

Sources: https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_HINT_Hierarchical_Neuron_Concept_Explainer_CVPR_2022_paper.pdf
Neurons can:
1) collaborative neurons contributing to a concept
2) multimodal neurons contributing to multiple concepts




## Concept alignment



- ConceptExplainer: Interactive Explanation for Deep Neural Networks from a Concept Perspective (I LOVE THIS PAPER)

- HINT: Hierarchical Neuron Concept Explainer (I LOVE THIS PAPER) - https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_HINT_Hierarchical_Neuron_Concept_Explainer_CVPR_2022_paper.pdf

- https://github.com/poloclub/neuro-cartography, https://arxiv.org/pdf/2108.12931


\item short description of each technique: Transparency of deep neural networks for medical image analysis: A review of interpretability methods - EVERYTHING WITH CONCEPTS SHOULD GO INTO CONCEPTS, THE REST INTO EXPLAINABILITY
\end{itemize}