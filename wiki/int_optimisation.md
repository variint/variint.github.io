# Interpretability / Optimisation


### Activation Maximisation / Deep Dream
Sources: https://distill.pub/2017/feature-visualization/ \cite{olah2017feature}
Feature visualization answers questions about what a network, or parts of a network, are looking for by generating examples.
Feature Visualization: How neural networks build up their understanding of images 
Feature Visualization by Optimization
CNNs are differentiable with respect to their inputs.
While conceptually simple, there are subtle challenges in getting the optimization to work
If we want to understand a layer as a whole, we can use the DeepDream objective , searching for images the layer finds “interesting.” 
Optimization isolates the causes of behavior from mere correlations. A neuron may not be detecting what you initially thought. - Buildings—or sky? mixed4a, Unit 492 
understand how neurons interact, and avoid high frequency artifacts. 


