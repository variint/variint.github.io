# Behavioural interpretability

## Introdcution

### Description
Behavioral interpretability analyses input-output relations.
May also be used for Measuring Faithfulness of Explainable Techniques

### 8. **Cross-Validation**
- **Definition**: Checks if the result hold up across different subsets of data or during cross-validation.
- **Method**: Validate the result different folds or splits of the data.
- **Purpose**: Ensures that the result are generalizable and not specific to a particular subset of data.

### 1. **Feature Attribution Consistency**
- **Definition**: Measures whether the importance scores assigned to features remain consistent under slight perturbations.
- **Method**: Evaluate if small changes in input lead to consistent changes in feature attributions.
- **Metric**: Consistency score or stability measure of feature importance across perturbations.

### 2. **Counterfactual Explanations**
- **Definition**: Examines if the explanations correctly predict the output changes when certain features are altered.
- **Method**: Generate counterfactuals and check if the explanation aligns with the changes in the model’s predictions.
- **Metric**: Accuracy of the explanation in predicting the outcome of counterfactual scenarios.

### 3. **Model Fidelity**
- **Definition**: Assesses how well the explanation technique reflects the behavior of the model it is explaining.
- **Method**: Compare explanations generated by the technique with the model’s decision boundaries or learned features.
- **Metric**: Fidelity score or agreement rate between the explanation and model’s internal representations.

### 4. **Human Evaluation**
- **Definition**: Involves human judges assessing the quality and reliability of the explanations.
- **Method**: Collect feedback from domain experts or end-users on how well the explanations align with their understanding of the model’s behavior.
- **Metric**: Qualitative scores or ratings from human evaluators regarding the clarity and accuracy of the explanations.

### 5. **Perturbation Analysis**
- **Definition**: Tests if explanations change in a meaningful way when input data is perturbed.
- **Method**: Apply perturbations to input data and observe if the explanations adjust accordingly.
- **Metric**: Degree of change in explanations relative to changes in input data.

### 1. **= Input Perturbation Check**
- **Definition**: Evaluates how small changes in the input affect the model’s output.
- **Method**: Apply small perturbations to the input data and observe if the model's predictions or explanations change in a consistent manner.
- **Purpose**: Ensures that the model and its explanations respond appropriately to slight variations in input.

### 6. **Consistency with Known Facts**
- **Definition**: Evaluates if the explanations are consistent with established knowledge or domain-specific facts.
- **Method**: Compare explanations with known information or domain expertise to assess alignment.
- **Metric**: Accuracy of explanations in reflecting established knowledge.

### 7. **Local vs. Global Consistency**
- **Definition**: Measures if the explanations are consistent at both local (individual predictions) and global (overall model behavior) levels.
- **Method**: Assess if local explanations for specific predictions align with global trends or patterns.
- **Metric**: Consistency score between local explanations and global model behavior.

### 8. **Visualization Comparison**
- **Definition**: Compares visual explanations with model predictions to check for alignment.
- **Method**: Use visualization tools to interpret explanations and compare them with model outputs.
- **Metric**: Visual alignment score or agreement between visual explanations and model predictions.

### 9. **Robustness Testing**
- **Definition**: Assesses if the explanation technique is robust to changes in model parameters or training data.
- **Method**: Test explanations across different model versions or datasets to evaluate robustness.
- **Metric**: Robustness score based on changes in explanations across different model settings.

### 10. **Simplification Test**
- **Definition**: Evaluates if simplifying the explanation maintains its accuracy in reflecting the model’s behavior.
- **Method**: Simplify explanations and check if the simplified versions still accurately represent the model’s decisions.
- **Metric**: Accuracy of simplified explanations compared to original, detailed explanations.


## References
```{bibliography}
:filter: docname in docnames
```
