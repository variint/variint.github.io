<p>
    DecentNet is a network that makes use of modularity and disentanglement in early layers. Each module (DecentBlock) is trained on a single concept which is derived from clustering small image patches. In order not to limit the network in learning complex representations, the DecentBlocks feed into a fusion module and subsequently into combined layers. We focus on the explainability of the fusion module's layers and channels that are the bridge between the DecentBlocks and combined layers to understand which of the less abstract early layer features contribute most to a prediction.
</p>

<!-- -->
<h3>Milestones</h3>

<p>
	<ul>
		<li>2022: Start of project as university coursework</li>
	</ul>
</p>


<!-- -->
<h3>Experiment: Clustering of Concepts (April 2023)</h3>

<b>Summary:</b>
<p>
	Multiple DecentBlocks are trained on different concepts and therefore should show different activations. The concepts are derived from clustered feature vectors of patches extracted from the image dataset.
</p>

<b>Pipeline:</b>
<p>
	<ol>
		<li>Extract patches from each image. Overlapping patches. Excluding patches that are black.</li>
		<li>Feature vectors for each patch were derived via a ShuffleNet that has been pre-trained on the ImageNet dataset.</li>
		<li>Clustering of the feature vectors were performed with k-means with k clusters. Random filtering of n samples for each cluster.</li>
		<li>DeepDream like images are generated. A single patch is used for a single quilted image. Image quilting is a technique for texture synthesis.</li>
		<li>Training of k DecentBlocks. 1 positive class, k-1 negative classes. Dataset imbalance is removed with Mixed Batch Sampler. Supervised Contrastive Loss is used due to it's nature of disentangling features</li>
	</ol>
</p>

<b>Results:</b>
<p>
	<ul>
		<li>Boxplots of the clusters showed that there are slight similarities between the cluster results and the human annotated segmentation masks. </li>
		<li>Activation maps showed that slightly different parts of the image were activated. The difference of activation maps from a concept-trained ShuffleNet compared to the ImageNet-trained ShuffleNet were bigger than two ShuffleNets trained on 2 different concepts.</li>
	</ul>
</p>

<b>Conclusion:</b>
<p>
	<ul>
		<li>The problem seems to be in the definition of a concept. Multiple classes may include vessels. Currently we take one class as the positive class and all others for the negative class. Hence, vessels can appear in both positive and negative classes.</li>
		<li>k-means may not be the best clustering technique since their clusters are approximately of the same size. Due to imbalanced feature types (lesions) the clusters should be density based. If using k-means, the elbow technique should be applied.</li>
	</ul>
</p>


</p>

<h3>Experiment: Use Concepts from Segmentation Masks (April 2023)</h3>

<b>Summary:</b>
<p>
		Due to non satisfactory results from the clustering, the manual segmentation masks were used to define concepts. In a later experiment this should be done by a revised clustering mechanism. For now we just want to proof, that the DecentBlocks actually differ if trained on different concepts. Each DecentBlock will again be trained by a positive and a negative class. This time it will be "vessel" vs "non-vessel", "drusen" vs "non-drusen", ...
</p>











