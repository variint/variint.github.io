<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
        <meta name="description" content="" />
        <meta name="author" content="" />
        <title>Variint</title>
        <!-- Favicon-->
        <link rel="icon" type="image/x-icon" href="assets/favicon.ico" />
        <!-- Font Awesome icons (free version)-->
        <script src="https://use.fontawesome.com/releases/v5.15.4/js/all.js" crossorigin="anonymous"></script>
        <!-- Google fonts-->
        <link href="https://fonts.googleapis.com/css?family=Montserrat:400,700" rel="stylesheet" type="text/css" />
        <link href="https://fonts.googleapis.com/css?family=Roboto+Slab:400,100,300,700" rel="stylesheet" type="text/css" />
        <!-- Core theme CSS (includes Bootstrap)-->
        <link href="css/styles.css" rel="stylesheet" />
    </head>
    <body id="page-top">
        <header class="masthead">
        <!-- Navigation-->
        <nav class="navbar navbar-expand-lg" id="mainNav">
            <div class="container">
                <a class="navbar-brand" href="index.html"><img src="assets/img/navbar-logo.svg" alt="Variint Logo" /></a>
                <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
                    Menu
                    <i class="fas fa-bars ms-1"></i>
                </button>
                <div class="collapse navbar-collapse" id="navbarResponsive">
                    <ul class="navbar-nav text-uppercase ms-auto py-4 py-lg-0">
                        
                        <li class="nav-item"><a class="nav-link nav-button" href="index.html">Home</a></li>
                        <li class="nav-item"><a class="nav-link nav-button" href="projects.html">Projects</a></li>
                        <li class="nav-item"><a class="nav-link nav-button" href="ideas.html">Ideas</a></li>
                        <li class="nav-item"><a class="nav-link nav-active" href="skills.html">Skills</a></li>

                    </ul>
                </div>
            </div>
        </nav>
        <!-- Masthead-->
            
                <div id="myBtnContainer">
                  <div class="masthead-subheading">Preparation for future SkillPaths on SkillDisplay</div>
                  
                </div>

        </header>


        <section class="page-section bg-white">



            <main class="container">
              <div class="text-center">
              <h3 class="section-subheading text-muted">These skills are defined in the #2early2read paper reading sessions. We use the hashtag <a href="https://twitter.com/search?q=%232early2read">#2early2read</a> on Twitter.</h3>
            </div>

              <div class="row mb-2">

                <!--
                <div class="col-md-6">
                  <div class="row g-0 border rounded overflow-hidden flex-md-row mb-4 shadow-sm h-md-250 position-relative">
                    <div class="col p-4 d-flex flex-column position-static">
                      <strong class="d-inline-block mb-2 text-primary">World</strong>
                      <h3 class="mb-0">Featured post</h3>
                      <div class="mb-1 text-muted">Nov 12</div>
                      <p class="card-text mb-auto">This is a wider card with supporting text below as a natural lead-in to additional content.</p>
                      <a href="#" class="stretched-link">Continue reading</a>
                    </div>
                    <div class="col-auto d-none d-lg-block">
                      <svg class="bd-placeholder-img" width="200" height="250" xmlns="http://www.w3.org/2000/svg" role="img" aria-label="Placeholder: Thumbnail" preserveAspectRatio="xMidYMid slice" focusable="false"><title>Placeholder</title><rect width="100%" height="100%" fill="#55595c"/><text x="50%" y="50%" fill="#eceeef" dy=".3em">Thumbnail</text></svg>

                    </div>
                  </div>
                </div>
                -->

                <!--  Skill -->
                <div class="col-md-6">
                  <div class="row g-0 border rounded overflow-hidden flex-md-row mb-4 shadow-sm h-md-250 position-relative">
                    <div class="col p-4 d-flex flex-column position-static">
                      <strong class="d-inline-block mb-2 text-warning">Image Processing</strong>
                      <h3 class="mb-0">Skill Draft: seamless editing of image regions</h3>
                      <p class="mb-auto">
                        <b>Description: </b><br>
                        Seamless cloning and other Poisson image editing techniques are methods to insert a source image region/texture/illumination/colour into a destination image region. Seamless cloning uses Poisson equations with Dirichlet boundary conditions for guided interpolation to avoid discontinuinities at edges between source and destination regions. There are two variations, importing gradients/normal cloning (using the texture/gradient) from the source region, and mixing gradients/mixed cloning, where a combination of the source and destination texture is used for the final clone result. 
                        <b>Goals:</b>
                        <ul>
                          <li> I know about Guided Interpolation and Poisson partial differential equations. </li>
                          <li> I know about the seamless importation of both opaque and transparent source image regions into a destination region.</li>
                          <li> I can distinguish between the Seamless cloning types importing gradients and mixing gradients. </li>
                          <li> I can list image transformation techniques that are defined by using a guidance field depending entirely on the original image.</li>
                        </ul>
                      <br>
                        <b>Links:</b>
                        <ul>
                          <li><a href="https://www.cs.jhu.edu/~misha/Fall07/Papers/Perez03.pdf">Contribution paper: Poisson Image Editing (Perez et al., 2003)</a></li>
                          <li><a href="https://learnopencv.com/seamless-cloning-using-opencv-python-cpp/">Tutorial: Seamless Cloning using OpenCV (Python, C++)</a></li>
                        </ul>
                      </p>
                    </div>
                  </div>
                </div>
                <!--  Skill -->

                <!--  Skill -->
                <div class="col-md-6">
                  <div class="row g-0 border rounded overflow-hidden flex-md-row mb-4 shadow-sm h-md-250 position-relative">
                    <div class="col p-4 d-flex flex-column position-static">
                      <strong class="d-inline-block mb-2 text-danger">Deep Learning</strong>
                      <h3 class="mb-0">Skill Draft: Semi-Supervised learning (SSL)</h3>

                      <p class="mb-auto">
                        <br>
                        <b>Description:</b> <br>
                        Semi-supervised learning combines a (small) labelled with a (bigger) unlabelled dataset to perform a task such as classification or segmentation.
                        <br>
                        <b>Goals:</b>
                        <ul>
                          <li> I know the difference between self-training and co-training. </li>
                          <li> I know multiple ways to implement SSL. </li>
                          <li> I can explain the mean-teacher approach. </li>
                          <li> I can name the main assumptions in SSL. </li>
                        </ul>
                        <br>
                        <b>Links:</b>
                        <ul>
                          <li> <a href="https://arxiv.org/abs/1703.01780">Contribution paper: Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results (Tarvainen et al., 2017)</a> </li>
                          <li> <a href="https://arxiv.org/abs/1804.06353">Review paper: Not-so-supervised: A survey of semi-supervised, multi-instance, and transfer learning in medical image analysis (Cheplygina et al., 2019) </a> </li>
                          <li> <a href="https://arxiv.org/abs/2006.05278">Review paper: An Overview of Deep Semi-Supervised Learning (Ouali et al., 2020)</a> </li>
                        </ul>
                      </p>

                    </div>
                  </div>
                </div>
                <!--  Skill -->

                <!--  Skill -->
                <div class="col-md-6">
                  <div class="row g-0 border rounded overflow-hidden flex-md-row mb-4 shadow-sm h-md-250 position-relative">
                    <div class="col p-4 d-flex flex-column position-static">
                      <strong class="d-inline-block mb-2 text-danger">Deep Learning</strong>
                      <h3 class="mb-0">Skill Draft: Multi-task learning</h3>

                      <p class="mb-auto">
                        <br>
                        <b>Description:</b> <br>
                        Multi-task learning trains a combined network with a separate output head for each task. It is distinguished between hard and soft parameter sharing.
                        <br>
                        <b>Goals:</b>
                        <ul>
                          <li> I know the difference between hard and soft parameter sharing. </li>
                          <li> I know different approaches of weighting losses. </li>
                        </ul>
                        <br>
                        <b>Links:</b>
                        <ul>
                          <li>
                          <a href="https://arxiv.org/abs/1812.00422">Application paper: A multi-task deep learning model for the classification of Age-related Macular Degeneration (Chen et al., 2018)</a>
                          </li>
                          <li>
                          <a href="https://arxiv.org/abs/2005.02561">Application paper: Multi-task pre-training of deep neural networks for digital pathology (Mormont et al., 2020)</a>
                          </li>
                          <li> <a href="https://arxiv.org/abs/2005.02561">Review paper: Multi-Task Learning with Deep Neural Networks: A Survey (Crawshaw, 2020)</a>
                        </ul>
                      </p>

                    </div>
                  </div>
                </div>
                <!--  Skill -->

                <!--  Skill -->
                <div class="col-md-6">
                  <div class="row g-0 border rounded overflow-hidden flex-md-row mb-4 shadow-sm h-md-250 position-relative">
                    <div class="col p-4 d-flex flex-column position-static">
                      <strong class="d-inline-block mb-2 text-danger">Deep Learning</strong>
                      <h3 class="mb-0">Skill Draft: Partial labels</h3>

                      <p class="mb-auto">
                        <br>
                        <b>Description:</b> <br>
                        The partial label problem appears when an image is only partly annotated. This affects the performance of a neural network negatively.
                        <br>
                        <b>Goals:</b>
                        <ul>
                          <li> I know how semi-supervision (e.g. co-training) can help with the partial label problem. </li>
                          <li> I know the difference between early-learning and memorisation.</li>
                        </ul>
                        <br>
                        <b>Links:</b>
                        <ul>
                          <li>
                          <a href="https://arxiv.org/abs/1908.10454">Review paper: Embracing Imperfect Datasets: A Review of Deep Learning Solutions for Medical Image Segmentation (Tajbakhsh et al., 2019)</a>
                          </li>
                          <li>
                          <a href="https://arxiv.org/abs/2110.03740">Contribution paper: A Adaptive Early-Learning Correction for Segmentation from Noisy Annotations (Liu et al., 2022)</a>
                          </li>
                        </ul>
                      </p>


                    </div>
                  </div>
                </div>
                <!--  Skill -->
               


              </div>

            </main>
               


            </div>
        </section>
        
        

        <!-- Footer-->
        <footer class="footer py-4 bg-blue">
            <div class="container">
                <div class="row align-items-center">
                    <div class="col-lg-4 text-lg-start">Copyright &copy; Variint 2022</div>
                    <div class="col-lg-4 my-3 my-lg-0">
                        <a class="btn btn-dark btn-social mx-2" href="https://www.twitter.com/variint"><i class="fab fa-twitter"></i></a>
                        <a class="btn btn-dark btn-social mx-2" href="https://www.github.com/chrisini"><i class="fab fa-github"></i></a>
                        <a class="btn btn-dark btn-social mx-2" href="https://www.linkedin.com/in/christina-elena-bornberg"><i class="fab fa-linkedin-in"></i></a>
                    </div>
                    <div class="col-lg-4 text-lg-end">
                    </div>
                </div>
            </div>
        </footer>
        
        <!-- Bootstrap core JS-->
        <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"></script>
        <!-- Core theme JS-->
        <script src="js/scripts.js"></script>
    </body>
</html>


